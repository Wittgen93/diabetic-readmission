# Итоговый отчет по проекту "Диабетические повторные госпитализации"

В этом репозитории находится единый ноутбук `7_Final_submission.ipynb`, который последовательно показывает весь рабочий процесс: от загрузки сырых данных до итоговых моделей и финальных выводов.

---

## 1. Подготовка данных (`1_data_preparation.ipynb`)

**Что сделано:**  
- Загрузили исходный CSV с информацией о госпитализациях диабетиков.
- Заменили все строки со значением "?" на NaN, посчитали долю пропусков в каждом столбце.
- Удалили столбцы, где более 80 процентов значений отсутствуют (`weight`, `max_glu_serum`, `A1Cresult`), а также служебные идентификаторы (`encounter_id`, `patient_nbr`) - они не полезны для модели.
- Оставшиеся пропуски заполнили меткой "Unknown".
- Преобразовали текстовый столбец `age` (например, "[30-40)") в числовое значение - средний возраст.
- Сохранили чистый датафрейм в `data/processed/df_clean.csv`.

**Зачем:**  
Чтобы все признаки имели корректный числовой или категориальный формат, пропуски не мешали обучению, и модель могла учиться без ошибок.

---

## 2. Исследовательский анализ (`2_exploratory_analysis.ipynb`)

**Что рассмотрели:**  
- Гистограммы для числовых признаков (время в стационаре, распределение возраста).
- Столбчатые диаграммы для категориальных переменных (раса, пол).
- Матрицу корреляций для поиска сильных связей между признаками.
- Распределение целевой переменной `readmitted`:
  - NO: примерно 54 процентов
  - больше 30 дней: примерно 35 процентов
  - меньше 30 дней: примерно 11 процентов

**Выводы:**  
- Большинство пациентов не возвращается в течение 30 дней, класс повторных госпитализаций малозаметен (11 процентов) - есть дисбаланс классов.
- Числовые признаки в целом без экстремальных выбросов, но требуют стандартизации.

---

## 3. Базовая модель классификации (`3_baseline_model.ipynb`)

**Что сделали:**  
- Перевели целевую переменную в бинарный формат: 1 - повторная госпитализация в течение 30 дней, 0 - все остальные случаи.
- Обучили логистическую регрессию с настройками по умолчанию.

**Результаты:**  
- ROC AUC: 0.637
- Precision (1): 0.17
- Recall (1): 0.48
- F1 (1): 0.25
- Accuracy: 0.68

**Почему так:**  
Логистическая регрессия проста и дает базовую оценку сложности задачи. Она служит отправной точкой для улучшения моделей.

---

## 4. Продвинутые модели (`4_advanced_models.ipynb`)

**Что пробовали:**  
- Случайный лес: AUC примерно 0.65, но почти нулевой recall для редкого класса.
- XGBoost (без настройки): AUC примерно 0.67, recall около 0.56, precision низкий.
- Нейросеть (Keras): AUC примерно 0.68, но тоже плохо находит повторные госпитализации.

**Итог:**  
Нейросеть и XGBoost немного лучше базовой логистической регрессии по AUC, но качество для "повторов" по-прежнему невысокое.

---

## 5. Настройка гиперпараметров (`5_hyperparameter_tuning.ipynb`)

**Как настраивали:**  
- Случайный перебор параметров XGBoost: n_estimators, max_depth, learning_rate, subsample, colsample_bytree, gamma.
- 30 запусков, 3-кратная кросс-валидация.

**Лучшие параметры:**  
- n_estimators: 300
- max_depth: 3
- learning_rate: 0.10
- subsample: 0.80
- colsample_bytree: 0.60
- gamma: 1

**Итоговая AUC:** 0.69

---

## 6. Регрессия длительности лечения (`6_regression_time_in_hospital.ipynb`)

**Что делали:**  
1. Baseline - всегда предсказывать медиану (MAE = 1.72 дня, RMSE = 2.28).
2. LinearRegression - результаты те же.
3. Ridge/Lasso:
   - Ridge (alpha=1): MAE = 1.71, RMSE = 2.27
   - Ridge (alpha=10): MAE = 1.71, RMSE = 2.26
   - Lasso после тюнинга - немного хуже Ridge.

**Вывод:**  
Ridge с alpha=10 показал лучший результат - средняя ошибка около 1.71 дня.


---

**Заключение**  
Вся работа собрана в ноутбуке `7_Final_submission.ipynb`. 

Его запуск даст полный повтор всех этапов: код, выводы, графики и рекомендации.